{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOcvVmDmbOB4kOrcvH9+c7O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jonruida/PFM-and-PEFM-for-Image-Anomaly-Detection-and-Segmentation/blob/main/Transferlearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gb-FKtHP8qNO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# URL del archivo en Dropbox (modificada para descarga directa)\n",
        "dropbox_url = \"https://www.dropbox.com/scl/fi/7vd2tqg5tduieq0bk7k6f/ZgZ_s3.zip?rlkey=70iefk1dtwva3py1fbrz444h7&st=mvqw6fpd&dl=1\"\n"
      ],
      "metadata": {
        "id": "5hwaNP_dCsMO"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Ruta donde se guardará el archivo descargado\n",
        "zip_path = '/content/ZgZ_s3.zip'\n",
        "\n",
        "# Ruta donde se extraerá el contenido del ZIP\n",
        "extract_path = \"/content/data\"\n",
        "\n",
        "# Crear el directorio de extracción si no existe\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# Descargar el archivo desde Dropbox\n",
        "try:\n",
        "    response = requests.get(dropbox_url)\n",
        "    response.raise_for_status()  # Verificar si la descarga fue exitosa\n",
        "    with open(zip_path, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "    print(\"Descarga exitosa.\")\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error al descargar el archivo: {e}\")\n",
        "    raise\n",
        "\n",
        "# Verificar si el archivo descargado es un archivo ZIP válido y extraerlo\n",
        "if zipfile.is_zipfile(zip_path):\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_path)\n",
        "        print(\"Extracción exitosa.\")\n",
        "    except zipfile.BadZipFile:\n",
        "        print(\"Error: El archivo no es un archivo ZIP válido o está corrupto.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error inesperado durante la extracción: {e}\")\n",
        "else:\n",
        "    print(\"Error: El archivo descargado no es un archivo ZIP válido.\")\n"
      ],
      "metadata": {
        "id": "IXaL7Ka-N_SV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfb3194f-c0fa-4359-f24d-8290bded3963"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Descarga exitosa.\n",
            "Extracción exitosa.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convertir a PNG"
      ],
      "metadata": {
        "id": "cbmlIGwyWvGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import glob\n",
        "\n",
        "def convertir_a_png(imagen_path, output_dir):\n",
        "    imagen = Image.open(imagen_path)\n",
        "    base_nombre = os.path.basename(imagen_path).split(\".\")[0]\n",
        "    output_path = os.path.join(output_dir, f\"{base_nombre}.png\")\n",
        "    imagen.save(output_path, \"PNG\")\n",
        "    return output_path\n",
        "\n",
        "# Directorios de entrada y salida\n",
        "malignas_path = '/content/data/Malignos--Output_S3/imgS3_rois'\n",
        "benignas_path = '/content/data/PAPANICOL--Output_S3/imgS3_rois'\n",
        "output_dir_malignas = '/content/data/Malignos--Output_S3/imgS3_rois_png'\n",
        "output_dir_benignas = '/content/data/PAPANICOL--Output_S3/imgS3_rois_png'\n",
        "\n",
        "# Crear los directorios de salida si no existen\n",
        "os.makedirs(output_dir_malignas, exist_ok=True)\n",
        "os.makedirs(output_dir_benignas, exist_ok=True)\n",
        "\n",
        "# Convertir imágenes malignas a PNG\n",
        "for img_path in glob.glob(os.path.join(malignas_path, '*.tif')):\n",
        "    convertir_a_png(img_path, output_dir_malignas)\n",
        "\n",
        "# Convertir imágenes benignas a PNG\n",
        "for img_path in glob.glob(os.path.join(benignas_path, '*.tif')):\n",
        "    convertir_a_png(img_path, output_dir_benignas)\n",
        "\n"
      ],
      "metadata": {
        "id": "mOkXaestVLl0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trocear imagenes"
      ],
      "metadata": {
        "id": "3sM-_OX6W_Aq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "from PIL import Image\n",
        "import glob\n",
        "\n",
        "# Directorios de origen\n",
        "dir_sin_anomalias = '/content/data/PAPANICOL--Output_S3/imgS3_rois_png'\n",
        "dir_con_anomalias = '/content/data/Malignos--Output_S3/imgS3_rois_png'\n",
        "\n",
        "# Directorios de destino\n",
        "dir_test = '/content/data/test'\n",
        "dir_train = '/content/data/train'\n",
        "\n",
        "# Crear directorios de test y train si no existen\n",
        "os.makedirs(dir_test, exist_ok=True)\n",
        "os.makedirs(dir_train, exist_ok=True)\n",
        "\n",
        "# Listar imágenes sin anomalías\n",
        "imagenes_sin_anomalias = [\n",
        "    \"10.png\", \"19.png\", \"27.png\", \"35.png\", \"43.png\", \"51.png\", \"5.png\", \"68.png\", \"76.png\", \"84.png\", \"92.png\",\n",
        "    \"11.png\", \"1.png\", \"28.png\", \"36.png\", \"44.png\", \"52.png\", \"60.png\", \"69.png\", \"77.png\", \"85.png\", \"93.png\",\n",
        "    \"12.png\", \"20.png\", \"29.png\", \"37.png\", \"45.png\", \"53.png\", \"61.png\", \"6.png\", \"78.png\", \"86.png\", \"94.png\",\n",
        "    \"13.png\", \"21.png\", \"2.png\", \"38.png\", \"46.png\", \"54.png\", \"62.png\", \"70.png\", \"79.png\", \"87.png\", \"95.png\",\n",
        "    \"14.png\", \"22.png\", \"30.png\", \"39.png\", \"47.png\", \"55.png\", \"63.png\", \"71.png\", \"7.png\", \"88.png\", \"96.png\",\n",
        "    \"15.png\", \"23.png\", \"31.png\", \"3.png\", \"48.png\", \"56.png\", \"64.png\", \"72.png\", \"80.png\", \"89.png\", \"97.png\",\n",
        "    \"16.png\", \"24.png\", \"32.png\", \"40.png\", \"49.png\", \"57.png\", \"65.png\", \"73.png\", \"81.png\", \"8.png\", \"98.png\",\n",
        "    \"17.png\", \"25.png\", \"33.png\", \"41.png\", \"4.png\", \"58.png\", \"66.png\", \"74.png\", \"82.png\", \"90.png\", \"9.png\",\n",
        "    \"18.png\", \"26.png\", \"34.png\", \"42.png\", \"50.png\", \"59.png\", \"67.png\", \"75.png\", \"83.png\", \"91.png\"\n",
        "]\n",
        "\n",
        "# Listar imágenes con anomalías\n",
        "imagenes_con_anomalias = [\n",
        "    \"1005124.png\", \"1005129.png\", \"1005133.png\", \"1005207.png\", \"1005211.png\", \"1005215.png\",\n",
        "    \"1005126.png\", \"1005130.png\", \"1005134.png\", \"1005208.png\", \"1005212.png\",\n",
        "    \"1005127.png\", \"1005131.png\", \"1005205.png\", \"1005209.png\", \"1005213.png\",\n",
        "    \"1005128.png\", \"1005132.png\", \"1005206.png\", \"1005210.png\", \"1005214.png\"\n",
        "]\n",
        "\n",
        "# Seleccionar aleatoriamente 21 imágenes sin anomalías para el test\n",
        "imagenes_sin_anomalias_test = random.sample(imagenes_sin_anomalias, 21)\n",
        "# Las restantes serán para el entrenamiento\n",
        "imagenes_sin_anomalias_train = list(set(imagenes_sin_anomalias) - set(imagenes_sin_anomalias_test))\n",
        "\n",
        "# Copiar imágenes sin anomalías a los directorios correspondientes\n",
        "for img in imagenes_sin_anomalias_test:\n",
        "    shutil.copy(os.path.join(dir_sin_anomalias, img), os.path.join(dir_test, img))\n",
        "\n",
        "for img in imagenes_sin_anomalias_train:\n",
        "    shutil.copy(os.path.join(dir_sin_anomalias, img), os.path.join(dir_train, img))\n",
        "\n",
        "# Copiar imágenes con anomalías al directorio de test\n",
        "for img in imagenes_con_anomalias:\n",
        "    shutil.copy(os.path.join(dir_con_anomalias, img), os.path.join(dir_test, img))\n",
        "\n",
        "# Función para trocear una imagen en N partes\n",
        "def trocear_imagen(imagen_path, filas, columnas, output_dir):\n",
        "    imagen = Image.open(imagen_path)\n",
        "    anchura, altura = imagen.size\n",
        "\n",
        "    altura_trozo = altura // filas\n",
        "    anchura_trozo = anchura // columnas\n",
        "\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    for i in range(filas):\n",
        "        for j in range(columnas):\n",
        "            trozo = imagen.crop((j * anchura_trozo, i * altura_trozo, (j + 1) * anchura_trozo, (i + 1) * altura_trozo))\n",
        "            trozo.save(os.path.join(output_dir, f'{os.path.basename(imagen_path).split(\".\")[0]}_{i}_{j}.png'))\n",
        "\n",
        "# Parámetros para trocear\n",
        "filas = 34\n",
        "columnas = 34\n",
        "\n",
        "# Trocear imágenes del conjunto de entrenamiento\n",
        "output_dir_train_troceadas = os.path.join(dir_train, 'good')\n",
        "for img_path in glob.glob(os.path.join(dir_train, '*.png')):\n",
        "    trocear_imagen(img_path, filas, columnas, output_dir_train_troceadas)\n",
        "\n",
        "# Trocear imágenes del conjunto de test\n",
        "output_dir_test_troceadas = os.path.join(dir_test, 'good')\n",
        "for img_path in glob.glob(os.path.join(dir_test, '*.png')):\n",
        "    trocear_imagen(img_path, filas, columnas, output_dir_test_troceadas)\n"
      ],
      "metadata": {
        "id": "5_gVPO-0jz_r"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/jonruida/PFM-and-PEFM-for-Image-Anomaly-Detection-and-Segmentation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBIKgp1DNoT4",
        "outputId": "4db4ad9c-a0f9-4eb6-c5b7-68972549f3e0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PFM-and-PEFM-for-Image-Anomaly-Detection-and-Segmentation'...\n",
            "remote: Enumerating objects: 113, done.\u001b[K\n",
            "remote: Counting objects: 100% (113/113), done.\u001b[K\n",
            "remote: Compressing objects: 100% (77/77), done.\u001b[K\n",
            "remote: Total 113 (delta 57), reused 78 (delta 28), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (113/113), 4.13 MiB | 26.92 MiB/s, done.\n",
            "Resolving deltas: 100% (57/57), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install loguru"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lv2LdpYqRHmD",
        "outputId": "9eb80127-202b-4aed-eb49-a8a75791e7a1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting loguru\n",
            "  Downloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/62.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: loguru\n",
            "Successfully installed loguru-0.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxWtntLdQJ7u",
        "outputId": "b5f1c8e5-f76b-4063-c519-c779aaa78643"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install thop\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyXGL0KDSJjW",
        "outputId": "29198349-669a-4da3-c153-9605028a1799"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting thop\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from thop) (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (4.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->thop) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->thop) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->thop)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->thop)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->thop)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->thop)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->thop)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->thop)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->thop)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->thop)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->thop)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->thop)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->thop)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->thop)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->thop) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->thop) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, thop\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 thop-0.1.1.post2209072238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/PFM-and-PEFM-for-Image-Anomaly-Detection-and-Segmentation/MB-PFM-ResNet.py --train --gpu_id 0 --batch_size 8 --epochs 200 --resize 256 --data_trans imagenet --loss_type l2norm+l2 --data_root /content/data/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvyB2FzuNzYc",
        "outputId": "ce8060ee-125a-4b65-c343-a84f1673c8b8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-06-04 17:35:06.274805: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-06-04 17:35:06.274867: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-06-04 17:35:06.276367: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-06-04 17:35:06.284400: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-06-04 17:35:07.680162: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "usage: STFPM_Center [-h] [--seed SEED] [--gpu_id GPU_ID] [--train] [--data_trans {navie,imagenet}]\n",
            "                    [--loss_type {l2norm+l2,l2,l1,consine,l2+consine}] [--agent_S AGENT_S]\n",
            "                    [--agent_T AGENT_T] [--epochs EPOCHS] [--batch_size BATCH_SIZE] [--lr2 LR2]\n",
            "                    [--lr3 LR3] [--lr4 LR4] [--weight_decay WEIGHT_DECAY]\n",
            "                    [--latent_dim LATENT_DIM] [--data_root DATA_ROOT] [--resize RESIZE]\n",
            "                    [--post_smooth POST_SMOOTH]\n",
            "STFPM_Center: error: unrecognized arguments: true\n"
          ]
        }
      ]
    }
  ]
}